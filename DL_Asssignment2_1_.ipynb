{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5DZDnSilZ5kroTWGDvta9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Statements"
      ],
      "metadata": {
        "id": "XA56e3tAaaq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os"
      ],
      "metadata": {
        "id": "a7PLrD40XRvp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1:Load Dakshina Dataset"
      ],
      "metadata": {
        "id": "An-yE5JMakZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dakshina_tsv(file_path):\n",
        "    latin, devanagari = [], []\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) >= 2:\n",
        "                latin.append(parts[0])\n",
        "                devanagari.append(parts[1])\n",
        "    return list(zip(latin, devanagari))\n",
        "\n",
        "# Update this to your actual file path\n",
        "base_path = '/content'\n",
        "\n",
        "train_pairs = load_dakshina_tsv(os.path.join(base_path, 'hi.translit.sampled.dev.tsv'))\n",
        "test_pairs = load_dakshina_tsv(os.path.join(base_path, 'hi.translit.sampled.test.tsv'))"
      ],
      "metadata": {
        "id": "hJ9mTru6acLQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Build Character Vocab"
      ],
      "metadata": {
        "id": "8fhtvXMycTjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_chars = sorted(list(set(\"\".join(x for x, _ in train_pairs))))\n",
        "target_chars = sorted(list(set(\"\".join(y for _, y in train_pairs))))\n",
        "\n",
        "input_char2idx = {ch: i + 1 for i, ch in enumerate(input_chars)}\n",
        "input_char2idx[\"<pad>\"] = 0\n",
        "target_char2idx = {ch: i + 1 for i, ch in enumerate(target_chars)}\n",
        "target_char2idx[\"<pad>\"] = 0\n",
        "target_char2idx[\"<sos>\"] = len(target_char2idx)\n",
        "target_char2idx[\"<eos>\"] = len(target_char2idx)\n",
        "idx2target_char = {i: ch for ch, i in target_char2idx.items()}\n",
        "\n",
        "MAX_LENGTH = max(max(len(x), len(y)) for x, y in train_pairs) + 2"
      ],
      "metadata": {
        "id": "sgAW3rRLaq3O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Dataset Class"
      ],
      "metadata": {
        "id": "3IYBLPbgcwXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharSeqDataset(Dataset):\n",
        "    def __init__(self, data_pairs):\n",
        "        self.data = data_pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src, tgt = self.data[idx]\n",
        "        src_seq = [input_char2idx[ch] for ch in src]\n",
        "        tgt_seq = [target_char2idx[\"<sos>\"]] + [target_char2idx[ch] for ch in tgt] + [target_char2idx[\"<eos>\"]]\n",
        "\n",
        "        src_seq += [input_char2idx[\"<pad>\"]] * (MAX_LENGTH - len(src_seq))\n",
        "        tgt_seq += [target_char2idx[\"<pad>\"]] * (MAX_LENGTH - len(tgt_seq))\n",
        "\n",
        "        return torch.tensor(src_seq), torch.tensor(tgt_seq[:-1]), torch.tensor(tgt_seq[1:])  # input, decoder_input, target"
      ],
      "metadata": {
        "id": "KK6bCUQUcwD_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4:Seq2Seq Model"
      ],
      "metadata": {
        "id": "Bvl6pX0pc_EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self, input_vocab_size, target_vocab_size, embedding_dim, hidden_dim, num_layers=1, cell_type='lstm'):\n",
        "        super().__init__()\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.encoder_embedding = nn.Embedding(input_vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.decoder_embedding = nn.Embedding(target_vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        rnn = {'rnn': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}[self.cell_type]\n",
        "        self.encoder = rnn(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.decoder = rnn(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.output_fc = nn.Linear(hidden_dim, target_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_embed = self.encoder_embedding(src)\n",
        "        tgt_embed = self.decoder_embedding(tgt)\n",
        "\n",
        "        _, hidden = self.encoder(src_embed)\n",
        "        output, _ = self.decoder(tgt_embed, hidden)\n",
        "\n",
        "        return self.output_fc(output)"
      ],
      "metadata": {
        "id": "WxSIs7eJbKyD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Training Loop"
      ],
      "metadata": {
        "id": "bj5KASu_dSbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_seq2seq(model, dataloader, criterion, optimizer, device, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for src, tgt_input, tgt_output in dataloader:\n",
        "            src, tgt_input, tgt_output = src.to(device), tgt_input.to(device), tgt_output.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src, tgt_input)\n",
        "            loss = criterion(output.view(-1, output.size(-1)), tgt_output.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")"
      ],
      "metadata": {
        "id": "TRDEoKYOdCwC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Prediction Function"
      ],
      "metadata": {
        "id": "HzSqCwmzdhRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_seq2seq(model, src_seq, device, max_len=MAX_LENGTH):\n",
        "    model.eval()\n",
        "    src_indices = [input_char2idx.get(ch, 0) for ch in src_seq]\n",
        "    src_indices += [input_char2idx[\"<pad>\"]] * (MAX_LENGTH - len(src_indices))\n",
        "    src_tensor = torch.tensor(src_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        src_embed = model.encoder_embedding(src_tensor)\n",
        "        _, hidden = model.encoder(src_embed)\n",
        "\n",
        "        decoder_input = torch.tensor([[target_char2idx[\"<sos>\"]]], device=device)\n",
        "        decoded = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            dec_embed = model.decoder_embedding(decoder_input)\n",
        "            output, hidden = model.decoder(dec_embed, hidden)\n",
        "            logits = model.output_fc(output.squeeze(1))\n",
        "            pred_id = logits.argmax(dim=1).item()\n",
        "            if idx2target_char[pred_id] == \"<eos>\":\n",
        "                break\n",
        "            decoded.append(idx2target_char.get(pred_id, \"\"))\n",
        "            decoder_input = torch.tensor([[pred_id]], device=device)\n",
        "\n",
        "    return ''.join(decoded)"
      ],
      "metadata": {
        "id": "IkEKa8KcdVS5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Run Everything"
      ],
      "metadata": {
        "id": "Ucwf8JukdtpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "embedding_dim = 64\n",
        "hidden_dim = 128\n",
        "num_layers = 1\n",
        "cell_type = 'lstm'\n",
        "\n",
        "input_vocab_size = len(input_char2idx)\n",
        "target_vocab_size = len(target_char2idx)\n",
        "\n",
        "train_dataset = CharSeqDataset(train_pairs)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = Seq2SeqModel(input_vocab_size, target_vocab_size, embedding_dim, hidden_dim,\n",
        "                     num_layers=num_layers, cell_type=cell_type).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_seq2seq(model, train_loader, criterion, optimizer, device, epochs=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RzhWbtkdk7E",
        "outputId": "da87f8ab-2e8c-482e-c149-078f4cb8e0df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.7329\n",
            "Epoch 2, Loss: 2.3646\n",
            "Epoch 3, Loss: 2.2421\n",
            "Epoch 4, Loss: 2.1575\n",
            "Epoch 5, Loss: 2.0840\n",
            "Epoch 6, Loss: 1.9645\n",
            "Epoch 7, Loss: 1.8369\n",
            "Epoch 8, Loss: 1.7081\n",
            "Epoch 9, Loss: 1.5545\n",
            "Epoch 10, Loss: 1.4080\n",
            "Epoch 11, Loss: 1.2676\n",
            "Epoch 12, Loss: 1.1332\n",
            "Epoch 13, Loss: 1.0291\n",
            "Epoch 14, Loss: 0.9357\n",
            "Epoch 15, Loss: 0.8505\n",
            "Epoch 16, Loss: 0.7946\n",
            "Epoch 17, Loss: 0.7328\n",
            "Epoch 18, Loss: 0.6909\n",
            "Epoch 19, Loss: 0.6409\n",
            "Epoch 20, Loss: 0.6010\n",
            "Epoch 21, Loss: 0.5739\n",
            "Epoch 22, Loss: 0.5543\n",
            "Epoch 23, Loss: 0.5237\n",
            "Epoch 24, Loss: 0.4963\n",
            "Epoch 25, Loss: 0.4794\n",
            "Epoch 26, Loss: 0.4586\n",
            "Epoch 27, Loss: 0.4321\n",
            "Epoch 28, Loss: 0.4224\n",
            "Epoch 29, Loss: 0.4074\n",
            "Epoch 30, Loss: 0.3881\n",
            "Epoch 31, Loss: 0.3803\n",
            "Epoch 32, Loss: 0.3775\n",
            "Epoch 33, Loss: 0.3600\n",
            "Epoch 34, Loss: 0.3554\n",
            "Epoch 35, Loss: 0.3267\n",
            "Epoch 36, Loss: 0.3353\n",
            "Epoch 37, Loss: 0.3135\n",
            "Epoch 38, Loss: 0.3042\n",
            "Epoch 39, Loss: 0.3024\n",
            "Epoch 40, Loss: 0.2872\n",
            "Epoch 41, Loss: 0.2832\n",
            "Epoch 42, Loss: 0.2752\n",
            "Epoch 43, Loss: 0.2751\n",
            "Epoch 44, Loss: 0.2636\n",
            "Epoch 45, Loss: 0.2642\n",
            "Epoch 46, Loss: 0.2559\n",
            "Epoch 47, Loss: 0.2473\n",
            "Epoch 48, Loss: 0.2438\n",
            "Epoch 49, Loss: 0.2427\n",
            "Epoch 50, Loss: 0.2293\n",
            "Epoch 51, Loss: 0.2299\n",
            "Epoch 52, Loss: 0.2231\n",
            "Epoch 53, Loss: 0.2425\n",
            "Epoch 54, Loss: 0.2257\n",
            "Epoch 55, Loss: 0.2186\n",
            "Epoch 56, Loss: 0.2150\n",
            "Epoch 57, Loss: 0.2090\n",
            "Epoch 58, Loss: 0.2049\n",
            "Epoch 59, Loss: 0.2001\n",
            "Epoch 60, Loss: 0.2012\n",
            "Epoch 61, Loss: 0.1994\n",
            "Epoch 62, Loss: 0.1949\n",
            "Epoch 63, Loss: 0.1919\n",
            "Epoch 64, Loss: 0.1906\n",
            "Epoch 65, Loss: 0.2004\n",
            "Epoch 66, Loss: 0.1838\n",
            "Epoch 67, Loss: 0.1837\n",
            "Epoch 68, Loss: 0.1821\n",
            "Epoch 69, Loss: 0.1754\n",
            "Epoch 70, Loss: 0.1787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Test Predictions"
      ],
      "metadata": {
        "id": "NXKubnyFeEki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSample Predictions on Test Set:\")\n",
        "for x, y in test_pairs[:10]:\n",
        "    prediction = predict_seq2seq(model, x, device)\n",
        "    print(f\"Input: {x} | Actual: {y} | Predicted: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9fep6B8d0Pn",
        "outputId": "012efc15-525d-4483-e072-8c4e4d4e0820"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions on Test Set:\n",
            "Input: अंक | Actual: ank | Predicted: ank\n",
            "Input: अंक | Actual: anka | Predicted: ank\n",
            "Input: अंकित | Actual: ankit | Predicted: ankit\n",
            "Input: अंकों | Actual: anakon | Predicted: ankon\n",
            "Input: अंकों | Actual: ankhon | Predicted: ankon\n",
            "Input: अंकों | Actual: ankon | Predicted: ankon\n",
            "Input: अंकोर | Actual: angkor | Predicted: ankor\n",
            "Input: अंकोर | Actual: ankor | Predicted: ankor\n",
            "Input: अंगारक | Actual: angaarak | Predicted: angarak\n",
            "Input: अंगारक | Actual: angarak | Predicted: angarak\n"
          ]
        }
      ]
    }
  ]
}
